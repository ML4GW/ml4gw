{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2254218",
   "metadata": {},
   "source": [
    "# Benchmark pytests in ml4gw\n",
    "## Commands\n",
    "Run `pytest tests/waveforms/cbc/test_cbc_waveforms.py --benchmark=N` to get testing data at N samples\n",
    "\n",
    "Run `python plot_benchmark.py` to a 2d histogram with chirp mass and mass ratio by default\n",
    "\n",
    "## Below is two seperate section explaining the plotting code and data collection code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce4120b",
   "metadata": {},
   "source": [
    "### Plotting Code\n",
    "The plotting code runs on the assumption that the data was saved with the benchmarking code as it infers what each file contains based on the saved now. The code below shows `plot_benchmark.ipynb` which plots a 2d histogram with chirp mass and mass ratio as the axis and error as the density. The plots can be adjusted by passing a different plotting function into `plot_tests` as well as updating the plotting_keys to reflect what parameters your want to plot; the lines associated to doing this are,\n",
    "```\n",
    "plotting_function(data[err_key], data[plotting_keys[1]], data[plotting_keys[2]], f\"{test}_{err_key}\")\n",
    "```\n",
    "where changing the data[X] inputs will change the inputs to your plotting function; this function is called on all error keys found where err_key is each unqiue error key.\n",
    "```\n",
    "plot_tests(tests, plotting_function=plot_err_chirp_mass, plotting_keys=['chirp_mass', 'mass_ratio'])\n",
    "```\n",
    "When calling plot_tests make sure to specifiy which plotting function you want to use and what keys you are using as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573c1057",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def load_data_from_h5(filename):\n",
    "    \"\"\"\n",
    "    Loads data from an HDF5 file while preserving the original structure.\n",
    "    args:\n",
    "        filename (str): The path to the HDF5 file.\n",
    "    returns:\n",
    "        data (dict): A dictionary containing the data from the HDF5 file.\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    with h5py.File(filename, \"r\") as f:\n",
    "        for group_key in tqdm(f.keys()): # Iterate over singular tests\n",
    "            h5_group = f[group_key]\n",
    "            if group_key not in data:\n",
    "                data[group_key] = {} # Adds group_key (params and errors) to data if it doesn't exist\n",
    "            for dataset_key in h5_group.keys():\n",
    "                dataset = h5_group[dataset_key] # add group do data dict\n",
    "                if dataset.shape == ():  # Check if the dataset is a scalar\n",
    "                    data[group_key][dataset_key] = np.array([dataset[()]])\n",
    "                else:\n",
    "                    data[group_key][dataset_key] = dataset[:]\n",
    "    return data\n",
    "\n",
    "def plot_err_chirp_mass(err, chirp_mass, mass_ratio, file):\n",
    "    \"\"\"\n",
    "    Plots the error data as a 2d historgram with chirp mass and\n",
    "    mass ratio as the axis.\n",
    "    \"\"\"\n",
    "    # Make sure the data is 1D\n",
    "    chirp_mass = np.asarray(chirp_mass).reshape(-1)\n",
    "    mass_ratio = np.asarray(mass_ratio).reshape(-1)\n",
    "    err = np.asarray(err).reshape(-1)\n",
    "\n",
    "    # Make plots\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    cmap = plt.get_cmap('viridis')\n",
    "    min_color = cmap(0.0)\n",
    "    cmap.set_under(min_color)\n",
    "    cmap.set_bad(min_color)\n",
    "    plt.hist2d(chirp_mass, mass_ratio, bins=250, norm=LogNorm(), weights=err, cmap=cmap)\n",
    "    plt.colorbar(label=\"Error\")\n",
    "    plt.xlabel(\"Chirp Mass\")\n",
    "    plt.ylabel(\"Mass Ratio\")\n",
    "    plt.title(\"Histogram of Differences between lal and ml4gw waveforms\")\n",
    "    plt.suptitle(f\"Total number of differences ({len(err)})\")\n",
    "    plt.show()\n",
    "    plt.savefig(f\"benchmark_plots/{file}_histogram.png\")\n",
    "    plt.close()\n",
    "    print(f\"Saved plot to benchmark_plots/{file}_histogram.png\")\n",
    "\n",
    "def plot_tests(tests, plotting_function=plot_err_chirp_mass, plotting_keys=['chirp_mass', 'mass_ratio']):\n",
    "    \"\"\"\n",
    "    Function to plot data using plot_err_chirp_mass.\n",
    "    args:\n",
    "        tests (list): List of tests to plot. (Uses these strings to find the files)\n",
    "    returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Loop through provided tests\n",
    "    for test in tests:\n",
    "        # Change this based on where data is stored and what it is called\n",
    "        file_prefix = \"benchmark_data\"\n",
    "        folder = \"benchmark_data\"\n",
    "        num_files = 2 # Number of data files to include in plots, 0 defaults to all files\n",
    "        start_file = 0 # Start file index\n",
    "\n",
    "        segmented_data = {} # Dictionary to hold segmented data as each file is loaded seperately before conjoining into one dataset\n",
    "        print(f\"Loading data for test: {test}\")\n",
    "\n",
    "        # Find all files matching the pattern if num_files = 0\n",
    "        if num_files == 0:\n",
    "            index = 0\n",
    "            while os.path.exists(f\"{folder}/{file_prefix}_{test}_{index}.h5\"): # Find all files with the test name\n",
    "                num_files += 1\n",
    "                print(f\"Found file: {file_prefix}_{test}_{index}.h5\")\n",
    "                index += 1\n",
    "            \n",
    "            if num_files == 0:\n",
    "                print(f\"No files found for test: {test}. Skipping...\")\n",
    "                continue  # Skip to the next test\n",
    "        \n",
    "        # Load data from each file\n",
    "        for i in range(num_files):\n",
    "            filename = f\"{folder}/{file_prefix}_{test}_{i + start_file}.h5\"\n",
    "            file_data = load_data_from_h5(filename)\n",
    "            print(f\"loaded data: {i + start_file}\")\n",
    "            if i not in segmented_data:\n",
    "                segmented_data[i] = {}\n",
    "            segmented_data[i].update(file_data)\n",
    "\n",
    "        # Find all the error keys to plot using file names\n",
    "        # Data files must have err in the file name or program will not recognize\n",
    "        err_keys = []\n",
    "        for file_key in segmented_data:\n",
    "            for dataset_key in segmented_data[file_key].keys():\n",
    "                for key in segmented_data[file_key][dataset_key].keys():\n",
    "                    if 'err' in key and key not in err_keys:\n",
    "                        err_keys.append(key)\n",
    "        \n",
    "        print(f\"Found error keys: {err_keys}\")\n",
    "\n",
    "        # Loop over segmented data to compile into one dataset using each unique err_key\n",
    "        for err_key in err_keys:\n",
    "            # Initialize data\n",
    "            data = {}\n",
    "            # Loop over segmented data to compile all datsets that contain specific err_key\n",
    "            for file_key in segmented_data:\n",
    "                for dataset_key in segmented_data[file_key].keys():\n",
    "                    if err_key in segmented_data[file_key][dataset_key].keys():\n",
    "                        for key in segmented_data[file_key][dataset_key]:\n",
    "                            if key not in data:\n",
    "                                data[key] = []\n",
    "                            data[key].extend(segmented_data[file_key][dataset_key][key])\n",
    "            \n",
    "            # Plot the err data\n",
    "            print(f\"Plotting {err_key}\")\n",
    "            plotting_function(data[err_key], data[plotting_keys[0]], data[plotting_keys[1]], f\"{test}_{err_key}\")\n",
    "\n",
    "# Example Usage\n",
    "tests = ['phenom_p', 'phenom_d']\n",
    "\n",
    "plot_tests(tests, plotting_function=plot_err_chirp_mass, plotting_keys=['chirp_mass', 'mass_ratio'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61e6ea4",
   "metadata": {},
   "source": [
    "### Data Collection Code\n",
    "Benchmarking code is the same as the normal pytest code i.e.\n",
    "```\n",
    "assert np.allclose(\n",
    "                1e21 * hp_lal_data.real, 1e21 * hp_ml4gw.real.numpy(), atol=1e-3\n",
    "            )\n",
    "```\n",
    "but loaded and saved with,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf92422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE\n",
    "test_1_hp_real_abs_err = np.max(np.abs(1e21 * hp_lal_data.real - 1e21 * hp_ml4gw.real.numpy()))\n",
    "\n",
    "data = {\n",
    "                \"test_1_hp_real_abs_err\": test_1_hp_real_abs_err\n",
    "        }\n",
    "def write_benchmark_data(filename, dataset):\n",
    "    \"\"\"Write benchmark data to an HDF5 file, creating a new group for each run.\"\"\"\n",
    "    try:\n",
    "        with h5py.File(f\"{filename}\", \"a\") as f:\n",
    "            # Iterate using numbers as group names\n",
    "            existing_groupnames = [int(name) for name in f.keys() if name.isdigit()]\n",
    "            if existing_groupnames:\n",
    "                next_groupname = max(existing_groupnames) + 1\n",
    "            else:\n",
    "                next_groupname = 0\n",
    "            groupname = str(next_groupname)\n",
    "            group = f.require_group(groupname)\n",
    "            # Create datasets for each key in the dataset dictionary\n",
    "            for key, data in dataset.items():\n",
    "                data = np.array(data, dtype=np.float32)\n",
    "                if key not in f:\n",
    "                    if data.ndim == 0:\n",
    "                        dset = group.create_dataset(key, data=data)\n",
    "                    else:\n",
    "                        dset = group.create_dataset(key, data=data, maxshape=(None,), compression=\"gzip\")\n",
    "                else:\n",
    "                    dset = f[key]\n",
    "                    if data.ndim == 0:\n",
    "                        dset[...] = data\n",
    "                    else:\n",
    "                        current_size = dset.shape[0]\n",
    "                        new_size = current_size + data.shape[0]\n",
    "                        dset.resize(new_size, axis=0)\n",
    "                        dset[current_size:new_size] = data\n",
    "            f.flush()\n",
    "    except Exception as e:\n",
    "        print(f\"Error writing data to file: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afec8b2",
   "metadata": {},
   "source": [
    "When calling pytest there is an additional option --benchmark=N where N is the number of samples you want to run the tests with. Additionally the data is saved and batched to save I/O on the device. The place to change this option is,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f164b04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_file_name(base_name, extension=\"h5\"):\n",
    "    \"\"\"Get the next available file name with a numeric suffix.\"\"\"\n",
    "    index = 0\n",
    "    while os.path.exists(f\"{base_name}_{index}.{extension}\") and get_file_size(f\"{base_name}_{index}.{extension}\") >= 0.05:\n",
    "        index += 1\n",
    "    return f\"{base_name}_{index}.{extension}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63caa8a",
   "metadata": {},
   "source": [
    "Where `while os.path.exists(f\"{base_name}_{index}.{extension}\") and get_file_size(f\"{base_name}_{index}.{extension}\") >= 0.05:` specifies how large you want each file to be before moving on as well as,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62e8e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@pytest.fixture()\n",
    "def batch_size():\n",
    "    return 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b3c64d",
   "metadata": {},
   "source": [
    "Being the batch size of testing data to be written to each file at a time.\n",
    "\n",
    "Another nice feature of pytest is the ability to select which tests to run in a particular file. To use this feature add the option `-k` follow with the name of the test function you want. In `test_cbc_waveforms.py` the three options are: `test_phenom_d`, `test_phenom_p`, and `test_taylor_f2`. A full example of a command would be to run,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a24f8d4",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "pytest --benchmark=100 -k test_phenom_d tests/waveforms/cbc/test_cbc_waveforms.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5365c971",
   "metadata": {},
   "source": [
    "This would start collecting 100 samples of testing data for ONLY the test for the phenom_d waveform generation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
